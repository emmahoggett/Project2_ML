{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpersNeuralNet import*\n",
    "\n",
    "# Load dataset and samples into a pandas data frame\n",
    "DATA_TRAIN_PATH = 'data/data_train.csv'\n",
    "data = load_data(DATA_TRAIN_PATH)\n",
    "\n",
    "\n",
    "DATA_TEST_PATH = 'data/sampleSubmission.csv'\n",
    "samples = load_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give number of users and movies\n",
    "n_users = data['user_id'].nunique()\n",
    "n_movies = data['movie_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer import*\n",
    "from model_generation import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer & Neurons Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "prev_neurons = 100\n",
    "prev_embedding = 50\n",
    "prev_dropout = 0.05\n",
    "\n",
    "# Maximal number of tested values \n",
    "max_nb_layers = 20\n",
    "max_nb_neurons = 200\n",
    "\n",
    "# Maximal number of iterations & initialization\n",
    "max_iter = 50\n",
    "n_iter = 0\n",
    "break_ind = 0\n",
    "max_accurracy = 0\n",
    "\n",
    "while (n_iter<max_iter):\n",
    "    # Compute the optimal number of layers\n",
    "    next_layer, accurracy_layer = layers(max_nb_layers, prev_neurons, prev_dropout,  prev_embedding, data)\n",
    "    if (accurracy_layer >= max_accurracy):\n",
    "        max_accurracy = accurracy_layer\n",
    "        prev_layer = next_layer\n",
    "    print('Max Accuracy :{}\\n'.format(max_accurracy))\n",
    "    # Compute the optimal number of neurons\n",
    "    next_neurons, accurracy_neurons = neurons(next_layer, max_nb_neurons, prev_dropout, prev_embedding, data)\n",
    "    if (accurracy_neurons >= max_accurracy):\n",
    "        max_accurracy = accurracy_neurons\n",
    "        prev_neurons = next_neurons\n",
    "    print('Max Accuracy :{}\\n'.format(max_accurracy))\n",
    "    n_iter+=1\n",
    "    print ('\\n New iteration\\n')\n",
    "\n",
    "model = generate(prev_layer, prev_neurons, prev_dropout, n_users, n_movies, prev_embedding)\n",
    "model.save('model_LayersNeurons.h5')\n",
    "print ('\\n Simulation finished \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers, Neurons, Dropout & Embedding Layer Optimization\n",
    "\n",
    "Need to run first \"Layers & Neurons Optimization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nb_embedding = 150\n",
    "\n",
    "n_iter = 0\n",
    "\n",
    "while (n_iter<max_iter):\n",
    "    # Compute the optimal factor for emedding layers\n",
    "    next_embedding, accurracy_embeddinglayers = embeddinglayer(prev_layer, prev_neurons, prev_dropout, max_nb_embedding, data)\n",
    "    if (accurracy_embeddinglayers>= max_accurracy):\n",
    "        max_accurracy = accurracy_embeddinglayers\n",
    "        prev_embedding = next_embedding\n",
    "    print('Max Accuracy :{}\\n'.format(max_accurracy))\n",
    "    # Compute the optimal number for dropout\n",
    "    next_dropout, accurracy_dropout = optimize_dropout(prev_layer, prev_neurons, prev_embedding, data)\n",
    "    if(accurracy_dropout>= max_accurracy):\n",
    "        max_accurracy = accurracy_dropout\n",
    "        prev_dropout = next_dropout\n",
    "    print('Max Accuracy :{}\\n'.format(max_accurracy))\n",
    "    # Compute the optimal number of layers\n",
    "    next_layer, accurracy_layer = layers(max_nb_layers, prev_neurons, prev_dropout,  prev_embedding, data)\n",
    "    if (accurracy_layer >= max_accurracy):\n",
    "        max_accurracy = accurracy_layer\n",
    "        prev_layer = next_layer\n",
    "    print('Max Accuracy :{}\\n'.format(max_accurracy))\n",
    "    # Compute the optimal number of neurons\n",
    "    next_neurons, accurracy_neurons = neurons(next_layer, max_nb_neurons, prev_dropout, prev_embedding, data)\n",
    "    if (accurracy_neurons >= max_accurracy):\n",
    "        max_accurracy = accurracy_neurons\n",
    "        prev_neurons = next_neurons\n",
    "    print('Max Accuracy :{}\\n'.format(max_accurracy))\n",
    "    n_iter+=1\n",
    "    print ('\\n New iteration\\n')\n",
    "    \n",
    "model = generate(prev_layer, prev_neurons, prev_dropout, n_users, n_movies, prev_embedding)\n",
    "model.save('model_LayersNeuronsDropEmbed.h5')\n",
    "print ('\\n Simulation Successfully Finished\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Neuronal Network\n",
    "- RMSE : 1.329\n",
    "- Secondary : -0.413\n",
    "- ID : 26039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_layer = 2\n",
    "prev_neurons = 80\n",
    "prev_dropout = 0.45\n",
    "prev_embedding = 10\n",
    "model = generate(prev_layer, prev_neurons, prev_dropout, n_users, n_movies, prev_embedding)\n",
    "model.save('model_LayersNeurons.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array, X_test_array, y_train, y_test, n_movies, n_users = setDataSet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 941561 samples, validate on 235391 samples\n",
      "Epoch 1/10\n",
      "941561/941561 [==============================] - 8s 9us/step - loss: 1.2488 - accuracy: 0.4573 - categorical_accuracy: 0.4573 - val_loss: 1.5743 - val_accuracy: 0.2773 - val_categorical_accuracy: 0.2773\n",
      "Epoch 2/10\n",
      "941561/941561 [==============================] - 9s 9us/step - loss: 1.2470 - accuracy: 0.4582 - categorical_accuracy: 0.4582 - val_loss: 1.5733 - val_accuracy: 0.2771 - val_categorical_accuracy: 0.2771\n",
      "Epoch 3/10\n",
      "941561/941561 [==============================] - 9s 10us/step - loss: 1.2455 - accuracy: 0.4593 - categorical_accuracy: 0.4593 - val_loss: 1.5763 - val_accuracy: 0.2783 - val_categorical_accuracy: 0.2783\n",
      "Epoch 4/10\n",
      "941561/941561 [==============================] - 9s 9us/step - loss: 1.2444 - accuracy: 0.4602 - categorical_accuracy: 0.4602 - val_loss: 1.5807 - val_accuracy: 0.2787 - val_categorical_accuracy: 0.2787\n",
      "Epoch 5/10\n",
      "941561/941561 [==============================] - 9s 9us/step - loss: 1.2433 - accuracy: 0.4607 - categorical_accuracy: 0.4607 - val_loss: 1.5744 - val_accuracy: 0.2791 - val_categorical_accuracy: 0.2791\n",
      "Epoch 6/10\n",
      "941561/941561 [==============================] - 9s 9us/step - loss: 1.2425 - accuracy: 0.4610 - categorical_accuracy: 0.4610 - val_loss: 1.5724 - val_accuracy: 0.2789 - val_categorical_accuracy: 0.2789\n",
      "Epoch 7/10\n",
      "941561/941561 [==============================] - 9s 9us/step - loss: 1.2414 - accuracy: 0.4611 - categorical_accuracy: 0.4611 - val_loss: 1.5751 - val_accuracy: 0.2798 - val_categorical_accuracy: 0.2798\n",
      "Epoch 8/10\n",
      "941561/941561 [==============================] - 9s 9us/step - loss: 1.2408 - accuracy: 0.4623 - categorical_accuracy: 0.4623 - val_loss: 1.5725 - val_accuracy: 0.2795 - val_categorical_accuracy: 0.2795\n",
      "Epoch 9/10\n",
      "941561/941561 [==============================] - 9s 10us/step - loss: 1.2399 - accuracy: 0.4625 - categorical_accuracy: 0.4625 - val_loss: 1.5879 - val_accuracy: 0.2787 - val_categorical_accuracy: 0.2787\n",
      "Epoch 10/10\n",
      "941561/941561 [==============================] - 9s 10us/step - loss: 1.2394 - accuracy: 0.4624 - categorical_accuracy: 0.4624 - val_loss: 1.5748 - val_accuracy: 0.2787 - val_categorical_accuracy: 0.2787\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train_array, y=y_train,  batch_size=1024, \n",
    "                             epochs=10,verbose=1,validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_enc = LabelEncoder()\n",
    "user_enc = LabelEncoder()\n",
    "samples ['user'] = user_enc.fit_transform(samples['user_id'].values)\n",
    "samples['movie'] = item_enc.fit_transform(samples['movie_id'].values)\n",
    "X_samples = samples[['user', 'movie']].values\n",
    "X_samples_array = [X_samples[:,0], X_samples[:,1]]\n",
    "\n",
    "#make predictions with model\n",
    "sample_pred = model.predict(X_samples_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05152712 0.16593911 0.4203472  0.24062006 0.12156641]\n",
      " [0.05441142 0.17377752 0.42906865 0.23178619 0.11095628]\n",
      " [0.01176349 0.05259233 0.28243184 0.41827196 0.23494038]\n",
      " ...\n",
      " [0.11927024 0.19266436 0.2946778  0.19256788 0.20081976]\n",
      " [0.11528388 0.17552482 0.25898227 0.17678757 0.27342156]\n",
      " [0.02192065 0.06789187 0.24458118 0.32865798 0.33694834]]\n"
     ]
    }
   ],
   "source": [
    "print (sample_pred)\n",
    "rating_samples = (np.argmax(sample_pred,1)+1).tolist()\n",
    "samples['rating'] = rating_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a csv file\n",
    "PATH_SUBMISSION = \"data/OptimizeSimplePrediction.csv\"\n",
    "create_csv(PATH_SUBMISSION, samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
