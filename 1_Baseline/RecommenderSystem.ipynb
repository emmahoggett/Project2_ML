{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequiste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "from itertools import groupby\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import*\n",
    "from preprocessing import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users : 10000, number of items: 1000\n"
     ]
    }
   ],
   "source": [
    "DATA_TRAIN_PATH = \"data/data_train.csv\"\n",
    "data = load_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reproductibility, remove seed from split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:963903\n",
      "Total number of nonzero elements in test data:213049\n"
     ]
    }
   ],
   "source": [
    "valid_ratings, train, test = split_data(data, min_num_ratings=0, p_test=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImplementingBaseline import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of baseline using the global mean: RMSE = [[1.11845219]].\n"
     ]
    }
   ],
   "source": [
    "baseline_global_mean(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of the baseline using the user mean: [[1.03154921]].\n"
     ]
    }
   ],
   "source": [
    "user_train_mean = baseline_user_mean(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of the baseline using the item mean: [[1.09518532]].\n"
     ]
    }
   ],
   "source": [
    "baseline_item_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Matrix Factorization using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factorization_SGD import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 20   # K in the lecture notes\n",
    "lambda_user = 0.07\n",
    "lambda_item = 0.07\n",
    "\n",
    "user_features, item_features = matrix_factorization_SGD(train, num_features, lambda_user, lambda_item) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data: 1.004158146666524.\n"
     ]
    }
   ],
   "source": [
    "nz_row, nz_col = test.nonzero()\n",
    "nz_test = list(zip(nz_row, nz_col))\n",
    "rmse = compute_error(test, user_features, item_features, nz_test)\n",
    "print(\"RMSE on test data: {}.\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users : 10000, number of items: 1000\n"
     ]
    }
   ],
   "source": [
    "DATA_FINAL_PATH = \"data/sampleSubmission.csv\"\n",
    "samples = load_data(DATA_FINAL_PATH)\n",
    "_, _, samples = condition_min_num_ratings(samples, min_num_ratings=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data: 0.9373349757846028.\n"
     ]
    }
   ],
   "source": [
    "nz_row, nz_col = samples.nonzero()\n",
    "nz_samples = list(zip(nz_row, nz_col))\n",
    "rmse = compute_error(samples, user_features, item_features, nz_samples)\n",
    "print(\"RMSE on final data: {}.\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = user_features.T.dot(item_features)\n",
    "data = read_txt(DATA_FINAL_PATH)[1:]\n",
    "data = [deal_line(line) for line in data]\n",
    "n = len(data)\n",
    "submission = np.zeros((n,1))\n",
    "for i in range(n):\n",
    "    submission[i] = np.clip(round(prediction[data[i][1]-1][data[i][0]-1]), 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import*\n",
    "DATA_SUBMISSION = \"data/submission_SGD_base.csv\"\n",
    "create_csv(data, submission, DATA_SUBMISSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline dot product method SGD without min_num_ratings - AICrowd : 1.046 and accuracy = 0.124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Matrix Factorization using ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training set: 1.0461942444412098.\n",
      "RMSE on training set: 1.0052915622886536.\n",
      "RMSE on training set: 0.9604959334444244.\n",
      "RMSE on training set: 0.9322063675112147.\n",
      "RMSE on training set: 0.9176293680582193.\n",
      "RMSE on training set: 0.9089827855485251.\n",
      "RMSE on training set: 0.9031774254316103.\n",
      "RMSE on training set: 0.8989765751272415.\n",
      "RMSE on training set: 0.8957947034586203.\n",
      "RMSE on training set: 0.8933086046771442.\n",
      "RMSE on training set: 0.8913200200734677.\n",
      "RMSE on training set: 0.88969905180654.\n",
      "RMSE on training set: 0.8883569517235577.\n",
      "RMSE on training set: 0.8872312181228207.\n",
      "RMSE on training set: 0.8862766964665765.\n",
      "RMSE on training set: 0.8854599947732238.\n",
      "RMSE on training set: 0.8847558745725553.\n",
      "RMSE on training set: 0.8841448704917563.\n",
      "RMSE on training set: 0.8836116930761472.\n",
      "RMSE on training set: 0.8831441388408044.\n",
      "RMSE on training set: 0.8827323326975046.\n",
      "RMSE on training set: 0.8823681907370562.\n",
      "RMSE on training set: 0.8820450311913263.\n",
      "RMSE on training set: 0.8817572867619501.\n",
      "RMSE on training set: 0.8815002875981989.\n",
      "RMSE on training set: 0.8812700944393563.\n",
      "RMSE on training set: 0.8810633680336616.\n",
      "RMSE on training set: 0.8808772652878485.\n",
      "RMSE on training set: 0.8807093555181859.\n",
      "RMSE on training set: 0.8805575521559522.\n",
      "RMSE on training set: 0.8804200566043436.\n",
      "RMSE on training set: 0.8802953118528568.\n",
      "RMSE on training set: 0.8801819640612609.\n",
      "RMSE on training set: 0.8800788307313352.\n",
      "RMSE on training set: 0.8799848743583462.\n"
     ]
    }
   ],
   "source": [
    "from helpers import*\n",
    "from factorization_ALS import*\n",
    "\n",
    "num_features = 20   # K in the lecture notes\n",
    "lambda_user = 0.081\n",
    "lambda_item = 0.081\n",
    "    \n",
    "user_features, item_features = matrix_factorization_ALS(train, num_features, lambda_user, lambda_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data: 0.9911709029489721.\n"
     ]
    }
   ],
   "source": [
    "nz_row, nz_col = test.nonzero()\n",
    "nz_test = list(zip(nz_row, nz_col))\n",
    "rmse = compute_error(test, user_features, item_features, nz_test)\n",
    "print(\"RMSE on test data: {}.\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users : 10000, number of items: 1000\n"
     ]
    }
   ],
   "source": [
    "DATA_FINAL_PATH = \"data/sampleSubmission.csv\"\n",
    "samples = load_data(DATA_FINAL_PATH)\n",
    "_, _, samples = condition_min_num_ratings(samples, min_num_ratings=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data: 0.7634478766929802.\n"
     ]
    }
   ],
   "source": [
    "nz_row, nz_col = samples.nonzero()\n",
    "nz_samples = list(zip(nz_row, nz_col))\n",
    "rmse = compute_error(samples, user_features, item_features, nz_samples)\n",
    "print(\"RMSE on test data: {}.\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = user_features.T.dot(item_features)\n",
    "data = read_txt(DATA_FINAL_PATH)[1:]\n",
    "data = [deal_line(line) for line in data]\n",
    "n = len(data)\n",
    "submission = np.zeros((n,1))\n",
    "for i in range(n):\n",
    "    submission[i] = np.clip(round(prediction[data[i][1]-1][data[i][0]-1]), 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import*\n",
    "DATA_SUBMISSION = \"data/submission_ALS_base.csv\"\n",
    "create_csv(data, submission, DATA_SUBMISSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline dot product method ALS without min_num_ratings - AICrowd : 1.072 and accuracy = 0.081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
