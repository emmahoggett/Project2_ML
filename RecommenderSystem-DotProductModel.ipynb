{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System - Tensor Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n",
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data\n",
    "\n",
    "DATA_TRAIN_PATH = \"data/data_train.csv\"\n",
    "ratings = load_data(DATA_TRAIN_PATH)\n",
    "\n",
    "DATA_TEST_PATH = \"data/sampleSubmission.csv\"\n",
    "samples = load_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from helpers import convert_train\n",
    "\n",
    "\n",
    "data, n_users, n_movies = convert_train(ratings)\n",
    "train, test = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "submission,_,_=convert_train(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a dot product model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating movie embedding path\n",
    "movie_input = Input(shape=[1], name=\"Movies-Input\")\n",
    "movie_embedding = Embedding(n_movies+1, 5, name=\"Movies-Embedding\")(movie_input)\n",
    "movie_vec = Flatten(name=\"Flatten-Movies\")(movie_embedding)\n",
    "\n",
    "# Creating user embedding path\n",
    "user_input = Input(shape=[1], name=\"User-Input\")\n",
    "user_embedding = Embedding(n_users+1, 5, name=\"User-Embedding\")(user_input)\n",
    "user_vec = Flatten(name=\"Flatten-Users\")(user_embedding)\n",
    "\n",
    "# Performing dot product and creating model\n",
    "prod = Dot(name=\"Dot-Product\", axes=1)([movie_vec, user_vec])\n",
    "model = Model([user_input, movie_input], prod)\n",
    "model.compile(loss = 'mse', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/emma-hoggett/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 6.3870\n",
      "Epoch 2/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 1.0462\n",
      "Epoch 3/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 1.0160\n",
      "Epoch 4/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 1.0146\n",
      "Epoch 5/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 1.0143\n",
      "Epoch 6/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 1.0136\n",
      "Epoch 7/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 1.0127\n",
      "Epoch 8/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 1.0121\n",
      "Epoch 9/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 1.0110\n",
      "Epoch 10/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 1.0093\n",
      "Epoch 11/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 1.0075\n",
      "Epoch 12/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 1.0046\n",
      "Epoch 13/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 1.0006\n",
      "Epoch 14/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9959\n",
      "Epoch 15/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9905\n",
      "Epoch 16/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9843\n",
      "Epoch 17/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.9783\n",
      "Epoch 18/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9723\n",
      "Epoch 19/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9662\n",
      "Epoch 20/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9608\n",
      "Epoch 21/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9552\n",
      "Epoch 22/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9504\n",
      "Epoch 23/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9460\n",
      "Epoch 24/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9423\n",
      "Epoch 25/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9390\n",
      "Epoch 26/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9360\n",
      "Epoch 27/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9334\n",
      "Epoch 28/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9315\n",
      "Epoch 29/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9295\n",
      "Epoch 30/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9279\n",
      "Epoch 31/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9264\n",
      "Epoch 32/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9251\n",
      "Epoch 33/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9242\n",
      "Epoch 34/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9231\n",
      "Epoch 35/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9218\n",
      "Epoch 36/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9211\n",
      "Epoch 37/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9203\n",
      "Epoch 38/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9195\n",
      "Epoch 39/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9188\n",
      "Epoch 40/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9182\n",
      "Epoch 41/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9175\n",
      "Epoch 42/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9169\n",
      "Epoch 43/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9165\n",
      "Epoch 44/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9161\n",
      "Epoch 45/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9153\n",
      "Epoch 46/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9151\n",
      "Epoch 47/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9147\n",
      "Epoch 48/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9145\n",
      "Epoch 49/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9138\n",
      "Epoch 50/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9137\n",
      "Epoch 51/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9133\n",
      "Epoch 52/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9130\n",
      "Epoch 53/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9127\n",
      "Epoch 54/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9125\n",
      "Epoch 55/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9121\n",
      "Epoch 56/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9120\n",
      "Epoch 57/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9115\n",
      "Epoch 58/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9112\n",
      "Epoch 59/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9110\n",
      "Epoch 60/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9109\n",
      "Epoch 61/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9107\n",
      "Epoch 62/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9104\n",
      "Epoch 63/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9102\n",
      "Epoch 64/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9100\n",
      "Epoch 65/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9098\n",
      "Epoch 66/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9097\n",
      "Epoch 67/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9095\n",
      "Epoch 68/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9095\n",
      "Epoch 69/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9092\n",
      "Epoch 70/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9090\n",
      "Epoch 71/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9089\n",
      "Epoch 72/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9087\n",
      "Epoch 73/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9085\n",
      "Epoch 74/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9084\n",
      "Epoch 75/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9082\n",
      "Epoch 76/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9082\n",
      "Epoch 77/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9081\n",
      "Epoch 78/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9079\n",
      "Epoch 79/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9078\n",
      "Epoch 80/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9077\n",
      "Epoch 81/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9075\n",
      "Epoch 82/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9074\n",
      "Epoch 83/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9072\n",
      "Epoch 84/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9072\n",
      "Epoch 85/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9069\n",
      "Epoch 86/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9069\n",
      "Epoch 87/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9067\n",
      "Epoch 88/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9067\n",
      "Epoch 89/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9065\n",
      "Epoch 90/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9066\n",
      "Epoch 91/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9063\n",
      "Epoch 92/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9062\n",
      "Epoch 93/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9062\n",
      "Epoch 94/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9059\n",
      "Epoch 95/150\n",
      "1059256/1059256 [==============================] - 8s 8us/step - loss: 0.9060\n",
      "Epoch 96/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9059\n",
      "Epoch 97/150\n",
      "1059256/1059256 [==============================] - 8s 8us/step - loss: 0.9059\n",
      "Epoch 98/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9057\n",
      "Epoch 99/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9055\n",
      "Epoch 100/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9055\n",
      "Epoch 101/150\n",
      "1059256/1059256 [==============================] - 8s 8us/step - loss: 0.9056\n",
      "Epoch 102/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9054\n",
      "Epoch 103/150\n",
      "1059256/1059256 [==============================] - 8s 8us/step - loss: 0.9053\n",
      "Epoch 104/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9052\n",
      "Epoch 105/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9051\n",
      "Epoch 106/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9050\n",
      "Epoch 107/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9050\n",
      "Epoch 108/150\n",
      "1059256/1059256 [==============================] - 8s 8us/step - loss: 0.9048\n",
      "Epoch 109/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9046\n",
      "Epoch 110/150\n",
      "1059256/1059256 [==============================] - 8s 8us/step - loss: 0.9047\n",
      "Epoch 111/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9045\n",
      "Epoch 112/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9044\n",
      "Epoch 113/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9044\n",
      "Epoch 114/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9044\n",
      "Epoch 115/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9043\n",
      "Epoch 116/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9043\n",
      "Epoch 117/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9042\n",
      "Epoch 118/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9040\n",
      "Epoch 119/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9040\n",
      "Epoch 120/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9040\n",
      "Epoch 121/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9041\n",
      "Epoch 122/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9038\n",
      "Epoch 123/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9040\n",
      "Epoch 124/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9037\n",
      "Epoch 125/150\n",
      "1059256/1059256 [==============================] - 8s 8us/step - loss: 0.9037\n",
      "Epoch 126/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9037\n",
      "Epoch 127/150\n",
      "1059256/1059256 [==============================] - 8s 8us/step - loss: 0.9036\n",
      "Epoch 128/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9036\n",
      "Epoch 129/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9033\n",
      "Epoch 130/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9033\n",
      "Epoch 131/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9032\n",
      "Epoch 132/150\n",
      "1059256/1059256 [==============================] - 8s 8us/step - loss: 0.9033\n",
      "Epoch 133/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9032\n",
      "Epoch 134/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9032\n",
      "Epoch 135/150\n",
      "1059256/1059256 [==============================] - 704s 665us/step - loss: 0.9030\n",
      "Epoch 136/150\n",
      "1059256/1059256 [==============================] - 8s 8us/step - loss: 0.9029\n",
      "Epoch 137/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.9030\n",
      "Epoch 138/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9028\n",
      "Epoch 139/150\n",
      "1059256/1059256 [==============================] - 9s 8us/step - loss: 0.9029\n",
      "Epoch 140/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9027\n",
      "Epoch 141/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9029\n",
      "Epoch 142/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9028\n",
      "Epoch 143/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9027\n",
      "Epoch 144/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9026\n",
      "Epoch 145/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9026\n",
      "Epoch 146/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9025\n",
      "Epoch 147/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.9024\n",
      "Epoch 148/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9026\n",
      "Epoch 149/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9024\n",
      "Epoch 150/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.9024\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "if os.path.exists('regression_model_dot_product.h5'):\n",
    "    model = load_model('regression_model_dot_product.h5')\n",
    "else:\n",
    "    history = model.fit([train.user_id, train.movie_id], train.rating, epochs=150,batch_size=200 ,verbose=1)\n",
    "    model.save('regression_model_dot_product.h5')\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Training Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117696/117696 [==============================] - 2s 14us/step\n",
      "Accuracy: 100.92%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate([test.user_id, test.movie_id], test.rating)\n",
    "\n",
    "predictions = model.predict([test.user_id, test.movie_id])\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (scores*100))\n",
    "\n",
    "predictions_dot= model.predict([submission.user_id, submission.movie_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dot = np.array([a[0] for a in predictions_dot])\n",
    "prediction_dot = np.rint(predictions_dot)\n",
    "\n",
    "prediction_dot = np.where(prediction_dot < 0, 0, prediction_dot)\n",
    "prediction_dot = np.where(prediction_dot > 5, 5, prediction_dot)\n",
    "\n",
    "\n",
    "\n",
    "submission.drop('rating',axis = 1, inplace = True)\n",
    "submission['rating'] = prediction_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import load_csv\n",
    "export_csv = load_csv('data/prediction_dot_product',submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
