{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System - Tensor Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n",
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data\n",
    "\n",
    "DATA_TRAIN_PATH = \"data/data_train.csv\"\n",
    "ratings = load_data(DATA_TRAIN_PATH)\n",
    "\n",
    "DATA_TEST_PATH = \"data/sampleSubmission.csv\"\n",
    "samples = load_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from helpers import convert_train\n",
    "\n",
    "\n",
    "data, n_users, n_movies = convert_train(ratings)\n",
    "train, test = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "submission,_,_=convert_train(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0        0         9       5\n",
       "1        0        60       5\n",
       "2        0        67       4\n",
       "3        0        83       4\n",
       "4        0       205       2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating movie embedding path\n",
    "movie_input = Input(shape = [1], name = \"Movies-Input\")\n",
    "movie_embedding = Embedding(n_movies + 1, 5, name = \"Movies-Embedding\")(movie_input)\n",
    "movie_vec = Flatten(name = \"Flatten-Movies\")(movie_embedding)\n",
    "\n",
    "# Creating user embedding path\n",
    "user_input = Input(shape = [1], name = \"User-Input\")\n",
    "user_embedding = Embedding(n_users + 1, 5, name = \"User-Embedding\")(user_input)\n",
    "user_vec = Flatten(name = \"Flatten-Users\")(user_embedding)\n",
    "\n",
    "# Concatenate features\n",
    "conc = Concatenate()([movie_vec, user_vec])\n",
    "\n",
    "# Add fully-connected-layers\n",
    "fc1 = Dense(128, activation = 'relu') (conc)\n",
    "fc2 = Dense(32, activation = 'relu') (fc1)\n",
    "out = Dense(1)(fc2)\n",
    "\n",
    "# Create model and compile\n",
    "model = Model([user_input, movie_input], out)\n",
    "model.compile('adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/emma-hoggett/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 1.1373\n",
      "Epoch 2/150\n",
      "1059256/1059256 [==============================] - 11s 11us/step - loss: 1.0004\n",
      "Epoch 3/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.9850\n",
      "Epoch 4/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.9766\n",
      "Epoch 5/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.9695\n",
      "Epoch 6/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.9629\n",
      "Epoch 7/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.9568\n",
      "Epoch 8/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.9507\n",
      "Epoch 9/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.9448\n",
      "Epoch 10/150\n",
      "1059256/1059256 [==============================] - 10s 10us/step - loss: 0.9380\n",
      "Epoch 11/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.9311\n",
      "Epoch 12/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.9246\n",
      "Epoch 13/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.9191\n",
      "Epoch 14/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.9149\n",
      "Epoch 15/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.9117\n",
      "Epoch 16/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.9089\n",
      "Epoch 17/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.9069\n",
      "Epoch 18/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.9049\n",
      "Epoch 19/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.9033\n",
      "Epoch 20/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.9016\n",
      "Epoch 21/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.9001\n",
      "Epoch 22/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.8990\n",
      "Epoch 23/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.8976\n",
      "Epoch 24/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8966\n",
      "Epoch 25/150\n",
      "1059256/1059256 [==============================] - 14s 13us/step - loss: 0.8952\n",
      "Epoch 26/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8943\n",
      "Epoch 27/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8932\n",
      "Epoch 28/150\n",
      "1059256/1059256 [==============================] - 10s 10us/step - loss: 0.8923\n",
      "Epoch 29/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.8914\n",
      "Epoch 30/150\n",
      "1059256/1059256 [==============================] - 10s 10us/step - loss: 0.8903\n",
      "Epoch 31/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8895\n",
      "Epoch 32/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8885\n",
      "Epoch 33/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8876\n",
      "Epoch 34/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8865\n",
      "Epoch 35/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8856\n",
      "Epoch 36/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8848\n",
      "Epoch 37/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8838\n",
      "Epoch 38/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8829\n",
      "Epoch 39/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8818\n",
      "Epoch 40/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8812\n",
      "Epoch 41/150\n",
      "1059256/1059256 [==============================] - 10s 10us/step - loss: 0.8802\n",
      "Epoch 42/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.8794\n",
      "Epoch 43/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8785\n",
      "Epoch 44/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8776\n",
      "Epoch 45/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8767\n",
      "Epoch 46/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8759\n",
      "Epoch 47/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8749\n",
      "Epoch 48/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8741\n",
      "Epoch 49/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8734\n",
      "Epoch 50/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.8726\n",
      "Epoch 51/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8715\n",
      "Epoch 52/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8709\n",
      "Epoch 53/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8700\n",
      "Epoch 54/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8692\n",
      "Epoch 55/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8684\n",
      "Epoch 56/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8676\n",
      "Epoch 57/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8671\n",
      "Epoch 58/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.8663\n",
      "Epoch 59/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.8657\n",
      "Epoch 60/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.8650\n",
      "Epoch 61/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.8644\n",
      "Epoch 62/150\n",
      "1059256/1059256 [==============================] - 11s 11us/step - loss: 0.8640\n",
      "Epoch 63/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8634\n",
      "Epoch 64/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8626\n",
      "Epoch 65/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8623\n",
      "Epoch 66/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8616\n",
      "Epoch 67/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8612\n",
      "Epoch 68/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8604\n",
      "Epoch 69/150\n",
      "1059256/1059256 [==============================] - 13s 13us/step - loss: 0.8599\n",
      "Epoch 70/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8595\n",
      "Epoch 71/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8591\n",
      "Epoch 72/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8585\n",
      "Epoch 73/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8580\n",
      "Epoch 74/150\n",
      "1059256/1059256 [==============================] - 13s 13us/step - loss: 0.8576\n",
      "Epoch 75/150\n",
      "1059256/1059256 [==============================] - 13s 13us/step - loss: 0.8571\n",
      "Epoch 76/150\n",
      "1059256/1059256 [==============================] - 14s 13us/step - loss: 0.8565\n",
      "Epoch 77/150\n",
      "1059256/1059256 [==============================] - 13s 13us/step - loss: 0.8561\n",
      "Epoch 78/150\n",
      "1059256/1059256 [==============================] - 14s 13us/step - loss: 0.8558\n",
      "Epoch 79/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8554\n",
      "Epoch 80/150\n",
      "1059256/1059256 [==============================] - 11s 11us/step - loss: 0.8551\n",
      "Epoch 81/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.8547\n",
      "Epoch 82/150\n",
      "1059256/1059256 [==============================] - 16s 15us/step - loss: 0.8542\n",
      "Epoch 83/150\n",
      "1059256/1059256 [==============================] - 14s 13us/step - loss: 0.8538\n",
      "Epoch 84/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8536\n",
      "Epoch 85/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8532\n",
      "Epoch 86/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8528\n",
      "Epoch 87/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8524\n",
      "Epoch 88/150\n",
      "1059256/1059256 [==============================] - 11s 11us/step - loss: 0.8523\n",
      "Epoch 89/150\n",
      "1059256/1059256 [==============================] - 11s 11us/step - loss: 0.8518\n",
      "Epoch 90/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.8515\n",
      "Epoch 91/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.8513\n",
      "Epoch 92/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.8506\n",
      "Epoch 93/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.8503\n",
      "Epoch 94/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.8503\n",
      "Epoch 95/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.8498\n",
      "Epoch 96/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8495\n",
      "Epoch 97/150\n",
      "1059256/1059256 [==============================] - 10s 10us/step - loss: 0.8493\n",
      "Epoch 98/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8488\n",
      "Epoch 99/150\n",
      "1059256/1059256 [==============================] - 10s 10us/step - loss: 0.8487\n",
      "Epoch 100/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8485\n",
      "Epoch 101/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8481\n",
      "Epoch 102/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8479\n",
      "Epoch 103/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8475\n",
      "Epoch 104/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8470\n",
      "Epoch 105/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8472\n",
      "Epoch 106/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8468\n",
      "Epoch 107/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8465\n",
      "Epoch 108/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.8462\n",
      "Epoch 109/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.8461\n",
      "Epoch 110/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.8458\n",
      "Epoch 111/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8456\n",
      "Epoch 112/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8452\n",
      "Epoch 113/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.8450\n",
      "Epoch 114/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8449\n",
      "Epoch 115/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.8445\n",
      "Epoch 116/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8443\n",
      "Epoch 117/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8439\n",
      "Epoch 118/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8439\n",
      "Epoch 119/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8436\n",
      "Epoch 120/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8435\n",
      "Epoch 121/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8433\n",
      "Epoch 122/150\n",
      "1059256/1059256 [==============================] - 10s 10us/step - loss: 0.8429\n",
      "Epoch 123/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.8427\n",
      "Epoch 124/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8426\n",
      "Epoch 125/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8425\n",
      "Epoch 126/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8422\n",
      "Epoch 127/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.8419\n",
      "Epoch 128/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.8419\n",
      "Epoch 129/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8415\n",
      "Epoch 130/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.8415\n",
      "Epoch 131/150\n",
      "1059256/1059256 [==============================] - 16s 15us/step - loss: 0.8410\n",
      "Epoch 132/150\n",
      "1059256/1059256 [==============================] - 19s 18us/step - loss: 0.8413\n",
      "Epoch 133/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8411\n",
      "Epoch 134/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8410\n",
      "Epoch 135/150\n",
      "1059256/1059256 [==============================] - 19s 18us/step - loss: 0.8405\n",
      "Epoch 136/150\n",
      "1059256/1059256 [==============================] - 17s 16us/step - loss: 0.8402\n",
      "Epoch 137/150\n",
      "1059256/1059256 [==============================] - 19s 18us/step - loss: 0.8401\n",
      "Epoch 138/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8400\n",
      "Epoch 139/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8398\n",
      "Epoch 140/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8394\n",
      "Epoch 141/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8396\n",
      "Epoch 142/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8395\n",
      "Epoch 143/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8392\n",
      "Epoch 144/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8392\n",
      "Epoch 145/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8387\n",
      "Epoch 146/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8385\n",
      "Epoch 147/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8385\n",
      "Epoch 148/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8384\n",
      "Epoch 149/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8383\n",
      "Epoch 150/150\n",
      "1059256/1059256 [==============================] - 18s 17us/step - loss: 0.8380\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-531a223375cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'regression_model_neural_network.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "if os.path.exists('regression_model_neural_network.h5'):\n",
    "    model = load_model('regression_model_neural_network.h5')\n",
    "else:\n",
    "    history = model.fit([train.user_id, train.movie_id], train.rating, epochs=150,batch_size=200 ,verbose=1)\n",
    "    model.save('regression_model_neural_network.h5')\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Training Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117696/117696 [==============================] - 2s 14us/step\n",
      "Accuracy: 100.92%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate([test.user_id, test.movie_id], test.rating)\n",
    "\n",
    "predictions = model.predict([test.user_id, test.movie_id])\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (scores*100))\n",
    "\n",
    "predictions_dot= model.predict([submission.user_id, submission.movie_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 4. ... 2. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "predictions_dot = np.array([a[0] for a in predictions_dot])\n",
    "prediction_dot = np.rint(predictions_dot)\n",
    "\n",
    "prediction_dot = np.where(prediction_dot < 0, 0, prediction_dot)\n",
    "prediction_dot = np.where(prediction_dot > 5, 5, prediction_dot)\n",
    "\n",
    "\n",
    "\n",
    "submission.drop('rating',axis = 1, inplace = True)\n",
    "submission['rating'] = prediction_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import load_csv\n",
    "export_csv = load_csv('data/prediction_neural_network',submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
