{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System - Tensor Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n",
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data\n",
    "\n",
    "DATA_TRAIN_PATH = \"data/data_train.csv\"\n",
    "ratings = load_data(DATA_TRAIN_PATH)\n",
    "\n",
    "DATA_TEST_PATH = \"data/sampleSubmission.csv\"\n",
    "samples = load_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from helpers import convert_train\n",
    "\n",
    "\n",
    "data, n_users, n_movies = convert_train(ratings)\n",
    "train, test = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "submission,_,_=convert_train(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0        0         9       5\n",
       "1        0        60       5\n",
       "2        0        67       4\n",
       "3        0        83       4\n",
       "4        0       205       2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating movie embedding path\n",
    "movie_input = Input(shape = [1], name = \"Movies-Input\")\n",
    "movie_embedding = Embedding(n_movies + 1, 5, name = \"Movies-Embedding\")(movie_input)\n",
    "movie_vec = Flatten(name = \"Flatten-Movies\")(movie_embedding)\n",
    "\n",
    "# Creating user embedding path\n",
    "user_input = Input(shape = [1], name = \"User-Input\")\n",
    "user_embedding = Embedding(n_users + 1, 5, name = \"User-Embedding\")(user_input)\n",
    "user_vec = Flatten(name = \"Flatten-Users\")(user_embedding)\n",
    "\n",
    "# Concatenate features\n",
    "conc = Concatenate()([movie_vec, user_vec])\n",
    "\n",
    "# Add fully-connected-layers\n",
    "fc1 = Dense(128, activation = 'relu') (conc)\n",
    "fc2 = Dense(32, activation = 'relu') (fc1)\n",
    "out = Dense(1)(fc2)\n",
    "\n",
    "# Create model and compile\n",
    "model = Model([user_input, movie_input], out)\n",
    "model.compile('adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/emma-hoggett/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 1.1373\n",
      "Epoch 2/150\n",
      "1059256/1059256 [==============================] - 11s 11us/step - loss: 1.0004\n",
      "Epoch 3/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.9850\n",
      "Epoch 4/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.9766\n",
      "Epoch 5/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.9695\n",
      "Epoch 6/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.9629\n",
      "Epoch 7/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.9568\n",
      "Epoch 8/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.9507\n",
      "Epoch 9/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.9448\n",
      "Epoch 10/150\n",
      "1059256/1059256 [==============================] - 10s 10us/step - loss: 0.9380\n",
      "Epoch 11/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.9311\n",
      "Epoch 12/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.9246\n",
      "Epoch 13/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.9191\n",
      "Epoch 14/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.9149\n",
      "Epoch 15/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.9117\n",
      "Epoch 16/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.9089\n",
      "Epoch 17/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.9069\n",
      "Epoch 18/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.9049\n",
      "Epoch 19/150\n",
      "1059256/1059256 [==============================] - 12s 11us/step - loss: 0.9033\n",
      "Epoch 20/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.9016\n",
      "Epoch 21/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.9001\n",
      "Epoch 22/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.8990\n",
      "Epoch 23/150\n",
      "1059256/1059256 [==============================] - 12s 12us/step - loss: 0.8976\n",
      "Epoch 24/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8966\n",
      "Epoch 25/150\n",
      "1059256/1059256 [==============================] - 14s 13us/step - loss: 0.8952\n",
      "Epoch 26/150\n",
      "1059256/1059256 [==============================] - 13s 12us/step - loss: 0.8943\n",
      "Epoch 27/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8932\n",
      "Epoch 28/150\n",
      "1059256/1059256 [==============================] - 10s 10us/step - loss: 0.8923\n",
      "Epoch 29/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.8914\n",
      "Epoch 30/150\n",
      "1059256/1059256 [==============================] - 10s 10us/step - loss: 0.8903\n",
      "Epoch 31/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8895\n",
      "Epoch 32/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8885\n",
      "Epoch 33/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8876\n",
      "Epoch 34/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8865\n",
      "Epoch 35/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8856\n",
      "Epoch 36/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8848\n",
      "Epoch 37/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8838\n",
      "Epoch 38/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8829\n",
      "Epoch 39/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8818\n",
      "Epoch 40/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8812\n",
      "Epoch 41/150\n",
      "1059256/1059256 [==============================] - 10s 10us/step - loss: 0.8802\n",
      "Epoch 42/150\n",
      "1059256/1059256 [==============================] - 11s 10us/step - loss: 0.8794\n",
      "Epoch 43/150\n",
      "1059256/1059256 [==============================] - 10s 9us/step - loss: 0.8785\n",
      "Epoch 44/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8776\n",
      "Epoch 45/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8767\n",
      "Epoch 46/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8759\n",
      "Epoch 47/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8749\n",
      "Epoch 48/150\n",
      "1059256/1059256 [==============================] - 9s 9us/step - loss: 0.8741\n",
      "Epoch 49/150\n",
      "  65600/1059256 [>.............................] - ETA: 8s - loss: 0.8584"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "if os.path.exists('regression_model_neural_network.h5'):\n",
    "    model = load_model('regression_model_neural_network.h5')\n",
    "else:\n",
    "    history = model.fit([train.user_id, train.movie_id], train.rating, epochs=150,batch_size=200 ,verbose=1)\n",
    "    model1.save('regression_model_neural_network.h5')\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Training Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117696/117696 [==============================] - 2s 14us/step\n",
      "Accuracy: 100.92%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate([test.user_id, test.movie_id], test.rating)\n",
    "\n",
    "predictions = model.predict([test.user_id, test.movie_id])\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (scores*100))\n",
    "\n",
    "predictions_dot= model.predict([submission.user_id, submission.movie_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 4. ... 2. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "predictions_dot = np.array([a[0] for a in predictions_dot])\n",
    "prediction_dot = np.rint(predictions_dot)\n",
    "\n",
    "prediction_dot = np.where(prediction_dot < 0, 0, prediction_dot)\n",
    "prediction_dot = np.where(prediction_dot > 5, 5, prediction_dot)\n",
    "\n",
    "\n",
    "\n",
    "submission.drop('rating',axis = 1, inplace = True)\n",
    "submission['rating'] = prediction_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import load_csv\n",
    "export_csv = load_csv('data/prediction_neural_network',submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
